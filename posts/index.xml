<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Jihan Homepage</title>
    <link>http://jihan1218.github.io/posts/</link>
    <description>Recent content in Posts on Jihan Homepage</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <managingEditor>jihan1218@gmail.com (Jihan Kim)</managingEditor>
    <webMaster>jihan1218@gmail.com (Jihan Kim)</webMaster>
    <copyright>Â©2020, All Rights Reserved</copyright>
    <lastBuildDate>Tue, 18 Feb 2020 16:47:06 -0800</lastBuildDate>
    
        <atom:link href="http://jihan1218.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    
      
      <item>
        <title>K-Means Clustering</title>
        <link>http://jihan1218.github.io/posts/k-means-clustering/</link>
        <pubDate>Tue, 18 Feb 2020 16:47:06 -0800</pubDate>
        <author>jihan1218@gmail.com (Jihan Kim)</author>
        <guid>http://jihan1218.github.io/posts/k-means-clustering/</guid>
        <description>In this post, I&amp;rsquo;d like to discuss about one of basic unsupervised machine learning algorithms, k-means clustering.
Basic idea of k-means clustering is to find positions which minimize the variance of each cluster. In real world, the algorithm is widely used such as documen clustering, recommendation engines, image segmentation and customer segmentation.
K-means clustering algorithm steps:  Generate K initial centroids by selecting randomly from the data set Assign each data point with a cluster-label by finding the centroid which is the closest to the data Calculate new centroids by finding the first moment of each cluster over total number of data within the cluster Repeat 2 and 3 until centroids converge  Implementation In order to run this python code, we first need to import python libraries.</description>
      </item>
      
    
  </channel>
</rss>